{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['China', 'Germany', 'India', 'Japan', 'UK', 'USA']\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Path to data\n",
    "data_path = \"./dataset/training-GAN/\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "image_size = 64\n",
    "batch_size = 64\n",
    "noise_dim = 60\n",
    "num_epochs = 150\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  # Force all images to have the same size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "print(f\"Classes: {dataset.classes}\")\n",
    "print(f\"Number of classes: {len(dataset.classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], D Loss: 0.35599443316459656, G Loss: 1.694960594177246\n",
      "Epoch [2/150], D Loss: 0.6302751302719116, G Loss: 1.0635716915130615\n",
      "Epoch [3/150], D Loss: 0.6324901580810547, G Loss: 1.0196499824523926\n",
      "Epoch [4/150], D Loss: 0.6364952325820923, G Loss: 1.1025069952011108\n",
      "Epoch [5/150], D Loss: 0.6381392478942871, G Loss: 1.4775078296661377\n",
      "Epoch [6/150], D Loss: 0.5270842909812927, G Loss: 1.4302788972854614\n",
      "Epoch [7/150], D Loss: 0.5627069473266602, G Loss: 1.4136946201324463\n",
      "Epoch [8/150], D Loss: 0.4247141480445862, G Loss: 1.4889781475067139\n",
      "Epoch [9/150], D Loss: 0.43274739384651184, G Loss: 1.4742587804794312\n",
      "Epoch [10/150], D Loss: 0.3912230134010315, G Loss: 1.565316915512085\n",
      "Epoch [11/150], D Loss: 0.399790495634079, G Loss: 1.7438255548477173\n",
      "Epoch [12/150], D Loss: 0.36344772577285767, G Loss: 2.002863883972168\n",
      "Epoch [13/150], D Loss: 0.252550333738327, G Loss: 2.394333839416504\n",
      "Epoch [14/150], D Loss: 0.2634652554988861, G Loss: 2.4849693775177\n",
      "Epoch [15/150], D Loss: 0.2646951675415039, G Loss: 2.580556869506836\n",
      "Epoch [16/150], D Loss: 0.24080003798007965, G Loss: 2.7430880069732666\n",
      "Epoch [17/150], D Loss: 0.17829708755016327, G Loss: 3.056680679321289\n",
      "Epoch [18/150], D Loss: 0.138520747423172, G Loss: 3.255950689315796\n",
      "Epoch [19/150], D Loss: 0.15882760286331177, G Loss: 3.3127965927124023\n",
      "Epoch [20/150], D Loss: 0.19542476534843445, G Loss: 3.694384813308716\n",
      "Epoch [21/150], D Loss: 0.13733983039855957, G Loss: 3.521759271621704\n",
      "Epoch [22/150], D Loss: 0.11431536078453064, G Loss: 3.8303062915802\n",
      "Epoch [23/150], D Loss: 0.13300763070583344, G Loss: 3.744703769683838\n",
      "Epoch [24/150], D Loss: 0.11626969277858734, G Loss: 3.9751856327056885\n",
      "Epoch [25/150], D Loss: 0.14284105598926544, G Loss: 3.8597285747528076\n",
      "Epoch [26/150], D Loss: 0.13121263682842255, G Loss: 3.7762537002563477\n",
      "Epoch [27/150], D Loss: 0.12419315427541733, G Loss: 3.7005257606506348\n",
      "Epoch [28/150], D Loss: 0.11796022951602936, G Loss: 4.167278289794922\n",
      "Epoch [29/150], D Loss: 0.11682109534740448, G Loss: 3.840015172958374\n",
      "Epoch [30/150], D Loss: 0.13090826570987701, G Loss: 3.6143555641174316\n",
      "Epoch [31/150], D Loss: 0.11013227701187134, G Loss: 3.544571876525879\n",
      "Epoch [32/150], D Loss: 0.09290456771850586, G Loss: 3.6581740379333496\n",
      "Epoch [33/150], D Loss: 0.07666300237178802, G Loss: 4.2169084548950195\n",
      "Epoch [34/150], D Loss: 0.061901286244392395, G Loss: 4.525379180908203\n",
      "Epoch [35/150], D Loss: 0.07087094336748123, G Loss: 3.7665750980377197\n",
      "Epoch [36/150], D Loss: 0.07170362025499344, G Loss: 3.966747760772705\n",
      "Epoch [37/150], D Loss: 0.05959164723753929, G Loss: 4.191193103790283\n",
      "Epoch [38/150], D Loss: 0.053759217262268066, G Loss: 3.983746290206909\n",
      "Epoch [39/150], D Loss: 0.04428821802139282, G Loss: 4.804450511932373\n",
      "Epoch [40/150], D Loss: 0.05079663544893265, G Loss: 4.302340984344482\n",
      "Epoch [41/150], D Loss: 0.045578598976135254, G Loss: 4.353383541107178\n",
      "Epoch [42/150], D Loss: 0.04630407691001892, G Loss: 4.497439384460449\n",
      "Epoch [43/150], D Loss: 0.039766825735569, G Loss: 5.09965705871582\n",
      "Epoch [44/150], D Loss: 0.01754230260848999, G Loss: 6.661856651306152\n",
      "Epoch [45/150], D Loss: 0.044200215488672256, G Loss: 4.495306968688965\n",
      "Epoch [46/150], D Loss: 0.03454909846186638, G Loss: 4.875158786773682\n",
      "Epoch [47/150], D Loss: 0.027616985142230988, G Loss: 4.877974033355713\n",
      "Epoch [48/150], D Loss: 0.03512793779373169, G Loss: 4.782824516296387\n",
      "Epoch [49/150], D Loss: 0.036691538989543915, G Loss: 4.873924255371094\n",
      "Epoch [50/150], D Loss: 0.030162032693624496, G Loss: 5.1744384765625\n",
      "Epoch [51/150], D Loss: 0.12471716850996017, G Loss: 5.385476589202881\n",
      "Epoch [52/150], D Loss: 0.5030847787857056, G Loss: 7.6033549308776855\n",
      "Epoch [53/150], D Loss: 0.22542688250541687, G Loss: 4.3926005363464355\n",
      "Epoch [54/150], D Loss: 0.2645602226257324, G Loss: 4.422074317932129\n",
      "Epoch [55/150], D Loss: 0.7040879726409912, G Loss: 2.2390990257263184\n",
      "Epoch [56/150], D Loss: 0.3351559340953827, G Loss: 3.8000502586364746\n",
      "Epoch [57/150], D Loss: 0.2366161346435547, G Loss: 4.362156867980957\n",
      "Epoch [58/150], D Loss: 0.26909905672073364, G Loss: 2.807438373565674\n",
      "Epoch [59/150], D Loss: 0.1464955061674118, G Loss: 3.2011306285858154\n",
      "Epoch [60/150], D Loss: 0.14002305269241333, G Loss: 3.3268213272094727\n",
      "Epoch [61/150], D Loss: 0.09634663164615631, G Loss: 4.609389781951904\n",
      "Epoch [62/150], D Loss: 0.10427657514810562, G Loss: 4.997367858886719\n",
      "Epoch [63/150], D Loss: 0.0642135962843895, G Loss: 5.125629901885986\n",
      "Epoch [64/150], D Loss: 0.11670693755149841, G Loss: 3.288724422454834\n",
      "Epoch [65/150], D Loss: 0.08827033638954163, G Loss: 3.231013774871826\n",
      "Epoch [66/150], D Loss: 0.7693340182304382, G Loss: 1.7109142541885376\n",
      "Epoch [67/150], D Loss: 0.09645144641399384, G Loss: 3.104684829711914\n",
      "Epoch [68/150], D Loss: 0.11713661998510361, G Loss: 3.3216893672943115\n",
      "Epoch [69/150], D Loss: 0.11569295823574066, G Loss: 4.787379264831543\n",
      "Epoch [70/150], D Loss: 0.050304148346185684, G Loss: 3.9200668334960938\n",
      "Epoch [71/150], D Loss: 0.10270826518535614, G Loss: 2.9826066493988037\n",
      "Epoch [72/150], D Loss: 0.09790918976068497, G Loss: 3.7762317657470703\n",
      "Epoch [73/150], D Loss: 0.15638040006160736, G Loss: 3.405259847640991\n",
      "Epoch [74/150], D Loss: 0.5160680413246155, G Loss: 5.296090126037598\n",
      "Epoch [75/150], D Loss: 0.07123524695634842, G Loss: 3.652491807937622\n",
      "Epoch [76/150], D Loss: 0.1272408813238144, G Loss: 3.618049383163452\n",
      "Epoch [77/150], D Loss: 0.07984980940818787, G Loss: 3.6163558959960938\n",
      "Epoch [78/150], D Loss: 0.0982377752661705, G Loss: 3.50584077835083\n",
      "Epoch [79/150], D Loss: 0.3208337426185608, G Loss: 5.609076023101807\n",
      "Epoch [80/150], D Loss: 0.12332803755998611, G Loss: 5.320784091949463\n",
      "Epoch [81/150], D Loss: 0.04362276941537857, G Loss: 4.3005571365356445\n",
      "Epoch [82/150], D Loss: 0.0869312435388565, G Loss: 4.270204067230225\n",
      "Epoch [83/150], D Loss: 1.023081660270691, G Loss: 5.26937198638916\n",
      "Epoch [84/150], D Loss: 0.07471633702516556, G Loss: 3.977163553237915\n",
      "Epoch [85/150], D Loss: 0.11275944113731384, G Loss: 3.7818894386291504\n",
      "Epoch [86/150], D Loss: 0.1368243545293808, G Loss: 3.396772623062134\n",
      "Epoch [87/150], D Loss: 0.17593908309936523, G Loss: 3.7436463832855225\n",
      "Epoch [88/150], D Loss: 0.1782379001379013, G Loss: 3.6678662300109863\n",
      "Epoch [89/150], D Loss: 0.03663136810064316, G Loss: 5.175628185272217\n",
      "Epoch [90/150], D Loss: 0.12033969163894653, G Loss: 3.4203543663024902\n",
      "Epoch [91/150], D Loss: 0.27534064650535583, G Loss: 6.539287567138672\n",
      "Epoch [92/150], D Loss: 0.5113849639892578, G Loss: 3.06691837310791\n",
      "Epoch [93/150], D Loss: 0.37299060821533203, G Loss: 4.933216094970703\n",
      "Epoch [94/150], D Loss: 0.33693721890449524, G Loss: 1.8654870986938477\n",
      "Epoch [95/150], D Loss: 0.1264384686946869, G Loss: 2.8737802505493164\n",
      "Epoch [96/150], D Loss: 0.4975613057613373, G Loss: 0.7142666578292847\n",
      "Epoch [97/150], D Loss: 0.10382649302482605, G Loss: 4.28184175491333\n",
      "Epoch [98/150], D Loss: 0.20119048655033112, G Loss: 3.736145257949829\n",
      "Epoch [99/150], D Loss: 0.1357443928718567, G Loss: 3.6767351627349854\n",
      "Epoch [100/150], D Loss: 0.17877458035945892, G Loss: 3.61869215965271\n",
      "Epoch [101/150], D Loss: 0.11063108593225479, G Loss: 3.647939920425415\n",
      "Epoch [102/150], D Loss: 0.45680829882621765, G Loss: 0.3802768588066101\n",
      "Epoch [103/150], D Loss: 0.06983911246061325, G Loss: 4.155765533447266\n",
      "Epoch [104/150], D Loss: 0.20231252908706665, G Loss: 3.2596395015716553\n",
      "Epoch [105/150], D Loss: 0.1445842981338501, G Loss: 3.0248751640319824\n",
      "Epoch [106/150], D Loss: 0.16198457777500153, G Loss: 3.6273255348205566\n",
      "Epoch [107/150], D Loss: 0.8177295327186584, G Loss: 3.8059277534484863\n",
      "Epoch [108/150], D Loss: 0.12349781394004822, G Loss: 3.75298810005188\n",
      "Epoch [109/150], D Loss: 0.21526499092578888, G Loss: 2.3816757202148438\n",
      "Epoch [110/150], D Loss: 0.12852001190185547, G Loss: 3.0552785396575928\n",
      "Epoch [111/150], D Loss: 0.08190208673477173, G Loss: 4.424343109130859\n",
      "Epoch [112/150], D Loss: 0.40904808044433594, G Loss: 5.693023681640625\n",
      "Epoch [113/150], D Loss: 0.16722173988819122, G Loss: 3.6781046390533447\n",
      "Epoch [114/150], D Loss: 0.09417674690485, G Loss: 4.7625346183776855\n",
      "Epoch [115/150], D Loss: 0.374849408864975, G Loss: 4.9337663650512695\n",
      "Epoch [116/150], D Loss: 0.1279221475124359, G Loss: 4.959315299987793\n",
      "Epoch [117/150], D Loss: 0.14838065207004547, G Loss: 3.0242156982421875\n",
      "Epoch [118/150], D Loss: 0.3520926833152771, G Loss: 4.639291286468506\n",
      "Epoch [119/150], D Loss: 0.2529109716415405, G Loss: 1.7850812673568726\n",
      "Epoch [120/150], D Loss: 0.18896891176700592, G Loss: 3.991764545440674\n",
      "Epoch [121/150], D Loss: 0.290218710899353, G Loss: 5.273895263671875\n",
      "Epoch [122/150], D Loss: 0.49048230051994324, G Loss: 3.9931588172912598\n",
      "Epoch [123/150], D Loss: 0.2963489294052124, G Loss: 3.193563938140869\n",
      "Epoch [124/150], D Loss: 0.2278275191783905, G Loss: 3.1361167430877686\n",
      "Epoch [125/150], D Loss: 0.34728848934173584, G Loss: 1.8698959350585938\n",
      "Epoch [126/150], D Loss: 0.9078623056411743, G Loss: 3.0671164989471436\n",
      "Epoch [127/150], D Loss: 0.22833484411239624, G Loss: 4.169013023376465\n",
      "Epoch [128/150], D Loss: 0.11910971999168396, G Loss: 3.6726889610290527\n",
      "Epoch [129/150], D Loss: 0.20492680370807648, G Loss: 3.174219846725464\n",
      "Epoch [130/150], D Loss: 0.2546105980873108, G Loss: 2.604968547821045\n",
      "Epoch [131/150], D Loss: 0.1518019288778305, G Loss: 3.188908338546753\n",
      "Epoch [132/150], D Loss: 0.2303118258714676, G Loss: 2.7525341510772705\n",
      "Epoch [133/150], D Loss: 1.017554759979248, G Loss: 4.301434516906738\n",
      "Epoch [134/150], D Loss: 0.24949020147323608, G Loss: 4.147167205810547\n",
      "Epoch [135/150], D Loss: 0.4438268840312958, G Loss: 7.494129180908203\n",
      "Epoch [136/150], D Loss: 0.430363267660141, G Loss: 4.464613437652588\n",
      "Epoch [137/150], D Loss: 0.1703265905380249, G Loss: 2.957876682281494\n",
      "Epoch [138/150], D Loss: 1.5622047185897827, G Loss: 4.327082633972168\n",
      "Epoch [139/150], D Loss: 0.21691128611564636, G Loss: 2.995227336883545\n",
      "Epoch [140/150], D Loss: 0.17699503898620605, G Loss: 4.00440788269043\n",
      "Epoch [141/150], D Loss: 0.5055842995643616, G Loss: 2.2049167156219482\n",
      "Epoch [142/150], D Loss: 0.18362008035182953, G Loss: 3.5135657787323\n",
      "Epoch [143/150], D Loss: 0.49209409952163696, G Loss: 2.7696197032928467\n",
      "Epoch [144/150], D Loss: 0.6243677139282227, G Loss: 0.7714299559593201\n",
      "Epoch [145/150], D Loss: 0.10331940650939941, G Loss: 3.6616744995117188\n",
      "Epoch [146/150], D Loss: 0.30677899718284607, G Loss: 3.730644464492798\n",
      "Epoch [147/150], D Loss: 0.24197793006896973, G Loss: 3.6090362071990967\n",
      "Epoch [148/150], D Loss: 0.32924970984458923, G Loss: 4.038105010986328\n",
      "Epoch [149/150], D Loss: 0.22882825136184692, G Loss: 3.9107377529144287\n",
      "Epoch [150/150], D Loss: 0.4376823902130127, G Loss: 2.1937739849090576\n"
     ]
    }
   ],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, num_classes, image_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + num_classes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, image_channels * image_size * image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        input = torch.cat((noise, label_embed), dim=1)\n",
    "        output = self.model(input)\n",
    "        return output.view(output.size(0), 3, image_size, image_size)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes, image_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_channels * image_size * image_size + num_classes, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        images_flat = images.view(images.size(0), -1)\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        input = torch.cat((images_flat, label_embed), dim=1)\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(noise_dim, num_classes, 3).to(device)\n",
    "discriminator = Discriminator(num_classes, 3).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        batch_size = images.size(0)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "        fake_images = generator(noise, labels)\n",
    "        outputs = discriminator(fake_images.detach(), labels)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images, labels)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
    "\n",
    "    # Save generated images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(16, noise_dim).to(device)\n",
    "            labels = torch.randint(0, num_classes, (16,)).to(device)\n",
    "            fake_images = generator(noise, labels)\n",
    "            save_image(fake_images, f\"generated_images_epoch_{epoch+1}.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Generator.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mclasses)\n\u001b[0;32m     19\u001b[0m specific_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Replace with the desired label (e.g., class index 3)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mgenerate_specific_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecific_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerated_label_53.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[173], line 11\u001b[0m, in \u001b[0;36mgenerate_specific_image\u001b[1;34m(generator, label, noise_dim, image_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([label], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert label to tensor\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Generate image\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     generated_image \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Save image\u001b[39;00m\n\u001b[0;32m     14\u001b[0m save_image(generated_image, image_path, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\PanCh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PanCh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Generator.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Function to generate and save a specific image\n",
    "def generate_specific_image(generator, label, noise_dim, image_path=\"specific_image.png\"):\n",
    "    generator.eval()  # Set the generator to evaluation mode\n",
    "    \n",
    "    # Create noise vector and label tensor\n",
    "    noise = torch.randn(1, noise_dim).to(device)  # Generate a single noise vector\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).to(device)  # Convert label to tensor\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate image\n",
    "        generated_image = generator(noise, label_tensor)\n",
    "    \n",
    "    # Save image\n",
    "    save_image(generated_image, image_path, normalize=True)\n",
    "    print(f\"Generated image saved at: {image_path}\")\n",
    "\n",
    "# Example usage\n",
    "print(dataset.classes)\n",
    "specific_label = 1 # Replace with the desired label (e.g., class index 3)\n",
    "generate_specific_image(generator, specific_label, noise_dim, image_path=\"generated_label_53.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Step [0/3], D Loss: 1.3950, G Loss: 0.6811\n",
      "Epoch [1/100], Step [0/3], D Loss: 0.9470, G Loss: 0.6395\n",
      "Epoch [2/100], Step [0/3], D Loss: 0.9179, G Loss: 0.6858\n",
      "Epoch [3/100], Step [0/3], D Loss: 0.7930, G Loss: 0.8247\n",
      "Epoch [4/100], Step [0/3], D Loss: 0.8370, G Loss: 0.8477\n",
      "Epoch [5/100], Step [0/3], D Loss: 0.7703, G Loss: 0.7687\n",
      "Epoch [6/100], Step [0/3], D Loss: 0.6981, G Loss: 0.7686\n",
      "Epoch [7/100], Step [0/3], D Loss: 0.6818, G Loss: 0.7742\n",
      "Epoch [8/100], Step [0/3], D Loss: 0.6448, G Loss: 0.8171\n",
      "Epoch [9/100], Step [0/3], D Loss: 0.6113, G Loss: 0.8789\n",
      "Epoch [10/100], Step [0/3], D Loss: 0.6296, G Loss: 0.8841\n",
      "Epoch [11/100], Step [0/3], D Loss: 0.6398, G Loss: 0.8614\n",
      "Epoch [12/100], Step [0/3], D Loss: 0.6465, G Loss: 0.8603\n",
      "Epoch [13/100], Step [0/3], D Loss: 0.6004, G Loss: 0.8952\n",
      "Epoch [14/100], Step [0/3], D Loss: 0.5978, G Loss: 0.9719\n",
      "Epoch [15/100], Step [0/3], D Loss: 0.5592, G Loss: 0.9944\n",
      "Epoch [16/100], Step [0/3], D Loss: 0.5665, G Loss: 0.9038\n",
      "Epoch [17/100], Step [0/3], D Loss: 0.5849, G Loss: 1.0381\n",
      "Epoch [18/100], Step [0/3], D Loss: 0.5228, G Loss: 1.0039\n",
      "Epoch [19/100], Step [0/3], D Loss: 0.5514, G Loss: 1.0113\n",
      "Epoch [20/100], Step [0/3], D Loss: 0.4626, G Loss: 1.1585\n",
      "Epoch [21/100], Step [0/3], D Loss: 0.5296, G Loss: 1.0974\n",
      "Epoch [22/100], Step [0/3], D Loss: 0.3932, G Loss: 1.4092\n",
      "Epoch [23/100], Step [0/3], D Loss: 0.4591, G Loss: 1.2705\n",
      "Epoch [24/100], Step [0/3], D Loss: 0.3561, G Loss: 1.6691\n",
      "Epoch [25/100], Step [0/3], D Loss: 0.4103, G Loss: 1.6599\n",
      "Epoch [26/100], Step [0/3], D Loss: 0.3234, G Loss: 2.2383\n",
      "Epoch [27/100], Step [0/3], D Loss: 0.3861, G Loss: 1.9617\n",
      "Epoch [28/100], Step [0/3], D Loss: 0.2576, G Loss: 2.1784\n",
      "Epoch [29/100], Step [0/3], D Loss: 0.2750, G Loss: 2.1843\n",
      "Epoch [30/100], Step [0/3], D Loss: 1.4356, G Loss: 0.5963\n",
      "Epoch [31/100], Step [0/3], D Loss: 0.7431, G Loss: 0.8094\n",
      "Epoch [32/100], Step [0/3], D Loss: 0.5590, G Loss: 1.1642\n",
      "Epoch [33/100], Step [0/3], D Loss: 1.8931, G Loss: 0.5965\n",
      "Epoch [34/100], Step [0/3], D Loss: 1.0979, G Loss: 0.7105\n",
      "Epoch [35/100], Step [0/3], D Loss: 0.8614, G Loss: 0.6716\n",
      "Epoch [36/100], Step [0/3], D Loss: 0.7616, G Loss: 0.8314\n",
      "Epoch [37/100], Step [0/3], D Loss: 0.6281, G Loss: 1.2799\n",
      "Epoch [38/100], Step [0/3], D Loss: 0.3509, G Loss: 1.8709\n",
      "Epoch [39/100], Step [0/3], D Loss: 0.7412, G Loss: 1.0793\n",
      "Epoch [40/100], Step [0/3], D Loss: 0.8195, G Loss: 1.5180\n",
      "Epoch [41/100], Step [0/3], D Loss: 0.4973, G Loss: 1.3056\n",
      "Epoch [42/100], Step [0/3], D Loss: 0.5037, G Loss: 1.0613\n",
      "Epoch [43/100], Step [0/3], D Loss: 0.3895, G Loss: 1.2407\n",
      "Epoch [44/100], Step [0/3], D Loss: 0.2876, G Loss: 1.5517\n",
      "Epoch [45/100], Step [0/3], D Loss: 0.4192, G Loss: 0.9610\n",
      "Epoch [46/100], Step [0/3], D Loss: 1.0177, G Loss: 0.5885\n",
      "Epoch [47/100], Step [0/3], D Loss: 1.0173, G Loss: 0.6824\n",
      "Epoch [48/100], Step [0/3], D Loss: 0.7393, G Loss: 1.9745\n",
      "Epoch [49/100], Step [0/3], D Loss: 0.3234, G Loss: 1.6319\n",
      "Epoch [50/100], Step [0/3], D Loss: 0.4159, G Loss: 1.4924\n",
      "Epoch [51/100], Step [0/3], D Loss: 0.8975, G Loss: 0.5875\n",
      "Epoch [52/100], Step [0/3], D Loss: 0.7316, G Loss: 0.8396\n",
      "Epoch [53/100], Step [0/3], D Loss: 0.8215, G Loss: 0.8031\n",
      "Epoch [54/100], Step [0/3], D Loss: 0.4201, G Loss: 2.2403\n",
      "Epoch [55/100], Step [0/3], D Loss: 0.3985, G Loss: 1.7282\n",
      "Epoch [56/100], Step [0/3], D Loss: 0.6510, G Loss: 1.0198\n",
      "Epoch [57/100], Step [0/3], D Loss: 0.9968, G Loss: 0.6936\n",
      "Epoch [58/100], Step [0/3], D Loss: 0.8412, G Loss: 0.6494\n",
      "Epoch [59/100], Step [0/3], D Loss: 0.6387, G Loss: 0.9672\n",
      "Epoch [60/100], Step [0/3], D Loss: 0.3442, G Loss: 1.8971\n",
      "Epoch [61/100], Step [0/3], D Loss: 0.3475, G Loss: 1.1808\n",
      "Epoch [62/100], Step [0/3], D Loss: 1.4510, G Loss: 0.6346\n",
      "Epoch [63/100], Step [0/3], D Loss: 0.8204, G Loss: 0.7582\n",
      "Epoch [64/100], Step [0/3], D Loss: 0.5682, G Loss: 1.3717\n",
      "Epoch [65/100], Step [0/3], D Loss: 0.4365, G Loss: 1.9902\n",
      "Epoch [66/100], Step [0/3], D Loss: 0.3555, G Loss: 2.7468\n",
      "Epoch [67/100], Step [0/3], D Loss: 0.6866, G Loss: 1.0390\n",
      "Epoch [68/100], Step [0/3], D Loss: 0.5083, G Loss: 1.3023\n",
      "Epoch [69/100], Step [0/3], D Loss: 0.2880, G Loss: 2.0228\n",
      "Epoch [70/100], Step [0/3], D Loss: 0.3589, G Loss: 2.1123\n",
      "Epoch [71/100], Step [0/3], D Loss: 0.3541, G Loss: 2.9362\n",
      "Epoch [72/100], Step [0/3], D Loss: 0.3407, G Loss: 1.8498\n",
      "Epoch [73/100], Step [0/3], D Loss: 0.6600, G Loss: 0.9508\n",
      "Epoch [74/100], Step [0/3], D Loss: 0.2715, G Loss: 1.9727\n",
      "Epoch [75/100], Step [0/3], D Loss: 0.2318, G Loss: 2.0158\n",
      "Epoch [76/100], Step [0/3], D Loss: 0.2435, G Loss: 2.0363\n",
      "Epoch [77/100], Step [0/3], D Loss: 0.2452, G Loss: 1.5911\n",
      "Epoch [78/100], Step [0/3], D Loss: 0.3549, G Loss: 0.9471\n",
      "Epoch [79/100], Step [0/3], D Loss: 0.2109, G Loss: 2.1134\n",
      "Epoch [80/100], Step [0/3], D Loss: 0.2579, G Loss: 2.2480\n",
      "Epoch [81/100], Step [0/3], D Loss: 0.1273, G Loss: 3.0627\n",
      "Epoch [82/100], Step [0/3], D Loss: 2.5602, G Loss: 0.4177\n",
      "Epoch [83/100], Step [0/3], D Loss: 0.3473, G Loss: 1.9237\n",
      "Epoch [84/100], Step [0/3], D Loss: 0.5715, G Loss: 1.0744\n",
      "Epoch [85/100], Step [0/3], D Loss: 0.3840, G Loss: 1.0907\n",
      "Epoch [86/100], Step [0/3], D Loss: 0.1825, G Loss: 2.3007\n",
      "Epoch [87/100], Step [0/3], D Loss: 0.3158, G Loss: 1.9997\n",
      "Epoch [88/100], Step [0/3], D Loss: 0.5289, G Loss: 1.2049\n",
      "Epoch [89/100], Step [0/3], D Loss: 0.2350, G Loss: 2.1053\n",
      "Epoch [90/100], Step [0/3], D Loss: 0.1816, G Loss: 2.1060\n",
      "Epoch [91/100], Step [0/3], D Loss: 0.1322, G Loss: 2.7192\n",
      "Epoch [92/100], Step [0/3], D Loss: 0.1996, G Loss: 2.9546\n",
      "Epoch [93/100], Step [0/3], D Loss: 0.2645, G Loss: 2.1264\n",
      "Epoch [94/100], Step [0/3], D Loss: 0.2059, G Loss: 1.8048\n",
      "Epoch [95/100], Step [0/3], D Loss: 0.2115, G Loss: 2.3675\n",
      "Epoch [96/100], Step [0/3], D Loss: 0.2516, G Loss: 1.9240\n",
      "Epoch [97/100], Step [0/3], D Loss: 0.1535, G Loss: 2.7871\n",
      "Epoch [98/100], Step [0/3], D Loss: 0.1631, G Loss: 2.7398\n",
      "Epoch [99/100], Step [0/3], D Loss: 0.1113, G Loss: 3.2095\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "image_size = 64   # Image size (64x64)\n",
    "latent_dim = 100  # Latent vector size (random noise)\n",
    "epochs = 100\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Generator Model (Fully Connected)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 3 * image_size * image_size),  # Output size should match flattened image\n",
    "            nn.Tanh()  # To match the pixel values in the range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.model(z)\n",
    "        x = x.view(-1, 3, image_size, image_size)  # Reshape to image shape (3, 64, 64)\n",
    "        return x\n",
    "\n",
    "# Discriminator Model (Fully Connected)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * image_size * image_size, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability of real/fake\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# DataLoader (Image loading from folder)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Replace `your_dataset_folder` with your folder path\n",
    "dataset = datasets.ImageFolder(root=\"./dataset/training-GAN/US/\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize models, loss function, and optimizers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = imgs.to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        # Create labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train the Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Real images\n",
    "        outputs = discriminator(real_imgs)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        # Fake images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        outputs = discriminator(fake_imgs.detach())  # Detach to avoid training the generator\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train the Generator\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        outputs = discriminator(fake_imgs)\n",
    "        g_loss = criterion(outputs, real_labels)  # Want the generator to fool the discriminator\n",
    "        g_loss.backward()\n",
    "\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Print losses and save generated images\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                  f\"D Loss: {d_loss_real.item() + d_loss_fake.item():.4f}, \"\n",
    "                  f\"G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    # Save generated images at the end of each epoch\n",
    "    if epoch % 10 == 0:\n",
    "        save_image(fake_imgs.data[:25], f\"output_epoch_{epoch}.png\", nrow=5, normalize=True)\n",
    "\n",
    "# Optionally, save models\n",
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
