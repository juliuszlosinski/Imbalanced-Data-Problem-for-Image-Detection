{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to input imbalanced images folder: ./maritime-flags-dataset/imbalanced_flags/\n",
      "Path to output balanced images folder: ./maritime-flags-dataset/balanced_flags/\n",
      "Size of image: (128, 128, 3)\n",
      "Batch size: 128\n",
      "Number of epochs: 1\n",
      "Latent dimension: 100\n",
      "Learning rate: 0.002\n",
      "Beta: 0.5\n",
      "======= Autoencoder =======\n",
      "\n",
      "B: 200, Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv2d_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_01): ReLU()\n",
      "    (conv2d_02): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv2d_03): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (flatten_04): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_04): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (relu_04): ReLU()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear_01): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "    (unflatten_01): Unflatten(dim=1, unflattened_size=(256, 16, 16))\n",
      "    (conv_transpose2d_02): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv_transpose2d_03): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (conv_transpose2d_04): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (tanh_04): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Loss: 0.5847\n",
      "C: 200, Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv2d_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_01): ReLU()\n",
      "    (conv2d_02): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv2d_03): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (flatten_04): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_04): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (relu_04): ReLU()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear_01): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "    (unflatten_01): Unflatten(dim=1, unflattened_size=(256, 16, 16))\n",
      "    (conv_transpose2d_02): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv_transpose2d_03): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (conv_transpose2d_04): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (tanh_04): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Loss: 0.5863\n",
      "D: 200, Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv2d_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_01): ReLU()\n",
      "    (conv2d_02): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv2d_03): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (flatten_04): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_04): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (relu_04): ReLU()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear_01): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "    (unflatten_01): Unflatten(dim=1, unflattened_size=(256, 16, 16))\n",
      "    (conv_transpose2d_02): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv_transpose2d_03): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (conv_transpose2d_04): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (tanh_04): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Loss: 0.6473\n",
      "E: 200, Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv2d_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_01): ReLU()\n",
      "    (conv2d_02): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv2d_03): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (flatten_04): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_04): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (relu_04): ReLU()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear_01): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "    (unflatten_01): Unflatten(dim=1, unflattened_size=(256, 16, 16))\n",
      "    (conv_transpose2d_02): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv_transpose2d_03): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (conv_transpose2d_04): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (tanh_04): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Loss: 0.5492\n",
      "F: 200, Autoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv2d_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_01): ReLU()\n",
      "    (conv2d_02): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv2d_03): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (flatten_04): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_04): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (relu_04): ReLU()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear_01): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (relu_01): ReLU()\n",
      "    (unflatten_01): Unflatten(dim=1, unflattened_size=(256, 16, 16))\n",
      "    (conv_transpose2d_02): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_02): ReLU()\n",
      "    (conv_transpose2d_03): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (relu_03): ReLU()\n",
      "    (conv_transpose2d_04): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (tanh_04): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from balancers.configuration_reader import ConfigurationReader\n",
    "from balancers.augmentation import AugmentationBalancer\n",
    "from balancers.adasyn import ImageADASYN\n",
    "from balancers.smote import ImageSMOTE\n",
    "from balancers.autoencoder import AEBalancer\n",
    "from balancers.dgan import DGANBalancer\n",
    "from balancers.annotations import Annotations\n",
    "\n",
    "path_to_input_imbalanced_images_folder=\"./maritime-flags-dataset/imbalanced_flags/images\"\n",
    "path_to_output_balanced_images_folder=\"./maritime-flags-dataset/balanced_flags/images/\"\n",
    "path_to_output_balanced_images_annotations_folder=\"./maritime-flags-dataset/balanced_flags/labels/\"\n",
    "\n",
    "# 1. Reading configuration.\n",
    "configuration_reader = ConfigurationReader()\n",
    "configuration_reader.read(\"./configuration.json\")\n",
    "configuration_reader.print()\n",
    "\n",
    "# 2. Selecting mode for data balancing.\n",
    "mode = \"AE\"\n",
    "debug = True\n",
    "\n",
    "# 3. Starting data balancing.\n",
    "match mode:\n",
    "    case \"AUGMENTATION\":\n",
    "        print(f\"======= AUGMENTATION =======\\n\")\n",
    "        aug_balancer = AugmentationBalancer()\n",
    "        aug_balancer.fit(\n",
    "            path_to_input_image_folder=path_to_input_imbalanced_images_folder, \n",
    "            debug=debug\n",
    "        )\n",
    "        aug_balancer.balance(\n",
    "            path_to_output_image_folder=path_to_output_balanced_images_folder, \n",
    "            debug=debug\n",
    "        )\n",
    "        print(f\"============================\\n\")\n",
    "    case \"ADASYN\":\n",
    "        print(f\"========== ADASYN ==========\\n\")\n",
    "        adasyn_balancer = ImageADASYN()\n",
    "        adasyn_balancer.fit(\n",
    "            path_to_input_image_folder=path_to_input_imbalanced_images_folder,\n",
    "            width_of_image=configuration_reader.width_of_image,\n",
    "            height_of_image=configuration_reader.height_of_image\n",
    "        )\n",
    "        adasyn_balancer.balance(\n",
    "            path_to_output_image_folder=path_to_output_balanced_images_folder,\n",
    "            number_of_neighbors = configuration_reader.number_of_neighbors\n",
    "        )\n",
    "        print(f\"===========================\\n\")\n",
    "    case \"SMOTE\":\n",
    "        print(f\"========== SMOTE ==========\\n\")\n",
    "        smote_balancer = ImageSMOTE()\n",
    "        smote_balancer.fit(\n",
    "            path_to_input_image_folder=path_to_input_imbalanced_images_folder, \n",
    "            width_of_image=configuration_reader.width_of_image, \n",
    "            height_of_image=configuration_reader.height_of_image\n",
    "        )\n",
    "        smote_balancer.balance(\n",
    "            path_to_output_image_folder=path_to_output_balanced_images_folder\n",
    "        )\n",
    "        print(f\"===========================\\n\")\n",
    "    case \"DGAN\":\n",
    "        print(f\"========== DGAN ==========\\n\")\n",
    "        dgan_balancer = DGANBalancer()\n",
    "        dgan_balancer.fit(\n",
    "            path_to_input_image_folder=path_to_input_imbalanced_images_folder,\n",
    "            latent_dimension=configuration_reader.latent_dimension, \n",
    "            learning_rate=configuration_reader.learning_rate, \n",
    "            beta_01=configuration_reader.beta,\n",
    "            batch_size=configuration_reader.batch_size, \n",
    "            number_of_epochs=configuration_reader.number_of_epochs, \n",
    "            delta=configuration_reader.delta\n",
    "        )\n",
    "        dgan_balancer.balance(\n",
    "            path_to_output_image_folder=path_to_output_balanced_images_folder\n",
    "        )\n",
    "        print(f\"===========================\\n\")     \n",
    "    case \"AE\":\n",
    "        print(f\"======= Autoencoder =======\\n\")\n",
    "        ae_balancer = AEBalancer()\n",
    "        ae_balancer.fit(\n",
    "            path_to_input_image_folder=path_to_input_imbalanced_images_folder, \n",
    "            batch_size=configuration_reader.batch_size, \n",
    "            number_of_epochs=configuration_reader.number_of_epochs, \n",
    "            delta=configuration_reader.delta\n",
    "        )\n",
    "        ae_balancer.balance(\n",
    "            path_to_output_image_folder=path_to_output_balanced_images_folder,\n",
    "            debug=debug\n",
    "        )\n",
    "        print(f\"===========================\\n\")\n",
    "\n",
    "# 4. Creating annotations for new/balanced images.     \n",
    "annotator = Annotations()\n",
    "annotator.annotate(\n",
    "    path_to_input_images=path_to_output_balanced_images_folder,\n",
    "    path_to_output_annotations=path_to_output_balanced_images_annotations_folder\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
