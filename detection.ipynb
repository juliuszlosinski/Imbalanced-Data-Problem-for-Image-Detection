{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from formatter import YOLOFormatter\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "class YOLODetector:\n",
    "    def __init__(self, yolo_type=\"yolov8s.pt\"):\n",
    "        self.yolo_formatter = YOLOFormatter()\n",
    "        self.yolo_type = yolo_type\n",
    "        self.model = YOLO(yolo_type)\n",
    "    \n",
    "    def format_to_yolo_directories(self, images_source_directory, labels_source_directory):\n",
    "        images_target_directory = \"./datasets/yolo-maritime-flags-dataset/images/train/\"\n",
    "        labels_target_directory = \"./datasets/yolo-maritime-flags-dataset/labels/train/\"\n",
    "        self.yolo_formatter.delete_all_files_and_directories(images_target_directory)\n",
    "        self.yolo_formatter.delete_all_files_and_directories(labels_target_directory)\n",
    "        self.yolo_formatter.copy(images_source_directory, images_target_directory)\n",
    "        self.yolo_formatter.copy(labels_source_directory, labels_target_directory)\n",
    "    \n",
    "    def create_validation_set(self, images_source_directory, labels_source_directory, number_of_images_per_class):\n",
    "        images_target_directory = \"./datasets/yolo-maritime-flags-dataset/images/val/\"\n",
    "        labels_target_directory = \"./datasets/yolo-maritime-flags-dataset/labels/val/\"\n",
    "        if os.path.exists(images_target_directory):\n",
    "            self.yolo_formatter.delete_all_files_and_directories(images_target_directory)\n",
    "        if os.path.exists(labels_target_directory):\n",
    "            self.yolo_formatter.delete_all_files_and_directories(labels_target_directory)\n",
    "        os.makedirs(images_target_directory)\n",
    "        os.makedirs(labels_target_directory)\n",
    "        categories = os.listdir(images_source_directory)\n",
    "        for category in categories:\n",
    "            path_to_category = f\"{images_source_directory}/{category}\"\n",
    "            number_of_images = len(os.listdir(path_to_category)) # 400\n",
    "            lower_bound = 10\n",
    "            upper_bound = number_of_images\n",
    "            selected_images = [f\"{category}_{random.randint(lower_bound, upper_bound)}.jpg\" for _ in range(number_of_images_per_class)]\n",
    "            for image in selected_images:\n",
    "                source=f\"{path_to_category}/{image}\"\n",
    "                destination=f\"{images_target_directory}/{image}\"\n",
    "                shutil.copy(source, destination)\n",
    "                label=str(image).split(\".\")[0]+\".txt\"\n",
    "                path_to_source_label=f\"{labels_source_directory}/{category}/{label}\"\n",
    "                path_to_output_label=f\"{labels_target_directory}/{label}\"\n",
    "                shutil.copy(path_to_source_label, path_to_output_label)\n",
    "\n",
    "    def create_test_set(self,images_source_directory, labels_source_directory, number_of_images_per_class):\n",
    "        images_target_directory = \"./datasets/yolo-maritime-flags-dataset/images/test/\"\n",
    "        labels_target_directory = \"./datasets/yolo-maritime-flags-dataset/labels/test/\"\n",
    "        if os.path.exists(images_target_directory):\n",
    "            self.yolo_formatter.delete_all_files_and_directories(images_target_directory)\n",
    "        if os.path.exists(labels_target_directory):\n",
    "            self.yolo_formatter.delete_all_files_and_directories(labels_target_directory)\n",
    "        os.makedirs(images_target_directory)\n",
    "        os.makedirs(labels_target_directory)\n",
    "        categories = os.listdir(images_source_directory)\n",
    "        for category in categories:\n",
    "            path_to_category = f\"{images_source_directory}/{category}\"\n",
    "            number_of_images = len(os.listdir(path_to_category)) # 400\n",
    "            lower_bound = 10\n",
    "            upper_bound = number_of_images\n",
    "            selected_images = [f\"{category}_{random.randint(lower_bound, upper_bound)}.jpg\" for _ in range(number_of_images_per_class)]\n",
    "            for image in selected_images:\n",
    "                source=f\"{path_to_category}/{image}\"\n",
    "                destination=f\"{images_target_directory}/{image}\"\n",
    "                shutil.copy(source, destination)\n",
    "                label=str(image).split(\".\")[0]+\".txt\"\n",
    "                path_to_source_label=f\"{labels_source_directory}/{category}/{label}\"\n",
    "                path_to_output_label=f\"{labels_target_directory}/{label}\"\n",
    "                shutil.copy(path_to_source_label, path_to_output_label)\n",
    "    \n",
    "    def fit(self, configuration_file, image_size, number_of_epochs):\n",
    "        self.model.train(data=configuration_file, imgsz=image_size, epochs=number_of_epochs)\n",
    "        \n",
    "    def predict(self, path_to_image):\n",
    "        self.model(path_to_image, save=True, save_txt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.44 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.43  Python-3.11.6 torch-2.1.1+cpu CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=./data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=26\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2126110  ultralytics.nn.modules.head.Detect           [26, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11,145,662 parameters, 11,145,646 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Github-Imbalanced\\Current-\\Imbalanced-Data-Problem-for-Image-Detection\\datasets\\yolo-maritime-flags-dataset\\labels\\test.cache... 511 images, 0 backgrounds, 0 corrupt: 100%|██████████| 511/511 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Github-Imbalanced\\Current-\\Imbalanced-Data-Problem-for-Image-Detection\\datasets\\yolo-maritime-flags-dataset\\labels\\test.cache... 511 images, 0 backgrounds, 0 corrupt: 100%|██████████| 511/511 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PanCh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000333, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 128 train, 128 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.7391      3.749      1.193         15        128: 100%|██████████| 32/32 [00:19<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:09<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511     0.0758      0.377     0.0925     0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G     0.3133      2.881      1.015         15        128: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.305      0.492       0.21      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G     0.2336      2.223     0.9724         15        128: 100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.222       0.58      0.402      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G     0.2165      1.787     0.9742         15        128: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.425      0.609      0.549      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      0.199      1.525     0.9598         15        128: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:09<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511       0.55      0.752      0.704      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.2149      1.278     0.9585         15        128: 100%|██████████| 32/32 [00:17<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:09<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.691       0.76      0.791      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.1911      1.147     0.9489         15        128: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.761      0.753      0.836      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.1891      1.033     0.9463         15        128: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.827      0.827      0.892      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.1635     0.8766     0.9428         15        128: 100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.856      0.836      0.911      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.1544     0.7926     0.9261         15        128: 100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.876      0.849      0.927      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.43  Python-3.11.6 torch-2.1.1+cpu CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "Model summary (fused): 168 layers, 11,135,646 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        511        511      0.879      0.846      0.927      0.912\n",
      "                     A         20         20      0.822          1      0.995      0.995\n",
      "                     B         20         20      0.734          1      0.983      0.961\n",
      "                     C         20         20      0.918        0.7      0.894      0.886\n",
      "                     D         20         20      0.926       0.35      0.651      0.651\n",
      "                     E         20         20      0.784       0.45      0.732      0.726\n",
      "                     F         20         20      0.966          1      0.995      0.995\n",
      "                     G         20         20      0.649        0.9      0.883      0.883\n",
      "                     H         19         19          1      0.311      0.668      0.664\n",
      "                     I         19         19      0.867          1      0.995      0.995\n",
      "                     J         20         20          1      0.598      0.965      0.965\n",
      "                     K         18         18      0.654      0.722      0.819      0.761\n",
      "                     L         20         20      0.858       0.85      0.867       0.84\n",
      "                     M         20         20      0.838          1       0.99       0.99\n",
      "                     N         20         20      0.975          1      0.995      0.988\n",
      "                     O         18         18      0.577      0.987      0.971      0.883\n",
      "                     P         20         20      0.949          1      0.995      0.995\n",
      "                     Q         19         19      0.927      0.895      0.944      0.925\n",
      "                     R         20         20          1      0.992      0.995      0.995\n",
      "                     S         20         20      0.956       0.95       0.99       0.99\n",
      "                     T         20         20      0.987        0.4      0.833      0.833\n",
      "                     U         20         20      0.857          1      0.995      0.995\n",
      "                     V         19         19      0.972          1      0.995      0.935\n",
      "                     W         20         20      0.817          1      0.995      0.995\n",
      "                     X         20         20      0.949        0.9      0.964      0.891\n",
      "                     Y         19         19      0.978          1      0.995      0.983\n",
      "                     Z         20         20       0.89          1      0.995      0.995\n",
      "Speed: 0.1ms preprocess, 11.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "\n",
      "image 1/1 d:\\Github-Imbalanced\\Current-\\Imbalanced-Data-Problem-for-Image-Detection\\maritime-flags-dataset\\SMOTE_balanced_flags\\images\\A\\A_01.jpg: 128x128 2 As, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "1 label saved to runs\\detect\\train2\\labels\n"
     ]
    }
   ],
   "source": [
    "method=\"SMOTE\"\n",
    "yolo_type=\"yolov8s.pt\"\n",
    "path_to_test_image=f\"./maritime-flags-dataset/{method}_balanced_flags/images/A/A_01.jpg\"\n",
    "images_source_directory=f\"./maritime-flags-dataset/{method}_balanced_flags/images/\"\n",
    "labels_source_directory=f\"./maritime-flags-dataset/{method}_balanced_flags/labels/\"\n",
    "yolo_configuration_file=f\"./data.yaml\"\n",
    "validation_number_of_images_per_class=32\n",
    "test_number_of_images_per_class=20\n",
    "image_size=128\n",
    "number_of_epochs=10\n",
    "\n",
    "yolo_detector = YOLODetector(yolo_type=yolo_type)\n",
    "\"\"\"\n",
    "yolo_detector.format_to_yolo_directories(\n",
    "    images_source_directory=images_source_directory, \n",
    "    labels_source_directory=labels_source_directory\n",
    ")\n",
    "yolo_detector.create_validation_set(\n",
    "    images_source_directory=images_source_directory, \n",
    "    labels_source_directory=labels_source_directory, \n",
    "    number_of_images_per_class=validation_number_of_images_per_class\n",
    ")\n",
    "yolo_detector.create_test_set(\n",
    "    images_source_directory=images_source_directory, \n",
    "    labels_source_directory=labels_source_directory,\n",
    "    number_of_images_per_class=test_number_of_images_per_class\n",
    ")\n",
    "\"\"\"\n",
    "yolo_detector.fit(\n",
    "    image_size=image_size, \n",
    "    number_of_epochs=number_of_epochs,\n",
    "    configuration_file=yolo_configuration_file\n",
    ")\n",
    "yolo_detector.predict(\n",
    "    path_to_image=path_to_test_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Github-Imbalanced\\Current-\\Imbalanced-Data-Problem-for-Image-Detection\\maritime-flags-dataset\\SMOTE_balanced_flags\\images\\A\\A_01.jpg: 128x128 2 As, 38.0ms\n",
      "Speed: 0.6ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "1 label saved to runs\\detect\\train4\\labels\n"
     ]
    }
   ],
   "source": [
    "yolo_detector.predict(\n",
    "    path_to_image=path_to_test_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Github-Imbalanced\\Current-\\Imbalanced-Data-Problem-for-Image-Detection\\combined-maritime-flags\\combined_01.jpg: 128x128 1 H, 2 Ls, 21 Ns, 1 P, 17 Rs, 2 Xs, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "1 label saved to runs\\detect\\train5\\labels\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
      "obb: None\n",
      "orig_img: array([[[242, 233, 236],\n",
      "        [243, 235, 235],\n",
      "        [239, 234, 225],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[244, 235, 238],\n",
      "        [245, 237, 237],\n",
      "        [242, 237, 228],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[244, 237, 240],\n",
      "        [246, 241, 240],\n",
      "        [245, 240, 231],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[254, 254, 254],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (264, 349)\n",
      "path: 'd:\\\\Github-Imbalanced\\\\Current-\\\\Imbalanced-Data-Problem-for-Image-Detection\\\\combined-maritime-flags\\\\combined_01.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\train5'\n",
      "speed: {'preprocess': 0.9801387786865234, 'inference': 37.13083267211914, 'postprocess': 1.0001659393310547}]\n"
     ]
    }
   ],
   "source": [
    "results = yolo_detector.model(\"./combined-maritime-flags/combined_01.jpg\", save=True, save_txt=True,  iou=1.0, conf=0.001, classes=None)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
