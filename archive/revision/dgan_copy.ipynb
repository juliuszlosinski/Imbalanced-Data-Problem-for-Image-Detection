{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 64\n",
    "latent_dimension = 100\n",
    "number_of_epochs = 200\n",
    "learning_rate = 0.002\n",
    "beta_01 = 0.5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=image_size),\n",
    "    transforms.CenterCrop(size=image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]) # Normalizing to [-1, 1]\n",
    "])\n",
    "dataset_path = \"./dataset/training-GAN/Test/\"\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, latent_dimension):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # First layer\n",
    "        self.conv_transpose_2d_01 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=latent_dimension, out_channels=512, kernel_size=4,\n",
    "            stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_01 = torch.nn.BatchNorm2d(num_features=512)\n",
    "        self.relu_01 = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second layer\n",
    "        self.conv_transpose_2d_02 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=512, out_channels=256, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_02 = torch.nn.BatchNorm2d(num_features=256)\n",
    "        self.relu_02 = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Third layer\n",
    "        self.conv_transpose_2d_03 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=256, out_channels=128, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_03 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        self.relu_03 = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Fourth layer\n",
    "        self.conv_transpose_2d_04 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=128, out_channels=64, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_04 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        self.relu_04 = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Fifth layer\n",
    "        self.conv_transpose_2d_05 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=64, out_channels=3, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_transpose_2d_01(x)\n",
    "        x = self.batch_norm_2d_01(x)\n",
    "        x = self.relu_01(x)\n",
    "        \n",
    "        x = self.conv_transpose_2d_02(x)\n",
    "        x = self.batch_norm_2d_02(x)\n",
    "        x = self.relu_02(x)\n",
    "        \n",
    "        x = self.conv_transpose_2d_03(x)\n",
    "        x = self.batch_norm_2d_03(x)\n",
    "        x = self.relu_03(x)\n",
    "        \n",
    "        x = self.conv_transpose_2d_04(x)\n",
    "        x = self.batch_norm_2d_04(x)\n",
    "        x = self.relu_04(x)\n",
    "        \n",
    "        x = self.conv_transpose_2d_05(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # First layer\n",
    "        self.conv2d_01 = torch.nn.Conv2d(\n",
    "            in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.leaky_relu_01 = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        \n",
    "        # Second layer\n",
    "        self.conv2d_02 = torch.nn.Conv2d(\n",
    "            in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_02 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        self.leaky_relu_02 = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        \n",
    "        # Third layer\n",
    "        self.conv2d_03 = torch.nn.Conv2d(\n",
    "            in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_03 = torch.nn.BatchNorm2d(num_features=256)\n",
    "        self.leaky_relu_03 = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        \n",
    "        # Fourth layer\n",
    "        self.conv2d_04 = torch.nn.Conv2d(\n",
    "            in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.batch_norm_2d_04 = torch.nn.BatchNorm2d(num_features=512)\n",
    "        self.leaky_relu_04 = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        \n",
    "        # Fivth layer\n",
    "        self.conv2d_05 = torch.nn.Conv2d(\n",
    "            in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.sigmoid_05 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_01(x)\n",
    "        x = self.leaky_relu_01(x)\n",
    "        \n",
    "        x = self.conv2d_02(x)\n",
    "        x = self.batch_norm_2d_02(x)\n",
    "        x = self.leaky_relu_02(x)\n",
    "        \n",
    "        x = self.conv2d_03(x)\n",
    "        x = self.batch_norm_2d_03(x)\n",
    "        x = self.leaky_relu_03(x)\n",
    "        \n",
    "        x = self.conv2d_04(x)\n",
    "        x = self.batch_norm_2d_04(x)\n",
    "        x = self.leaky_relu_04(x)\n",
    "        \n",
    "        x = self.conv2d_05(x)\n",
    "        x = self.sigmoid_05(x)\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator: Generator(\n",
      "  (conv_transpose_2d_01): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (batch_norm_2d_01): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_01): ReLU(inplace=True)\n",
      "  (conv_transpose_2d_02): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_02): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_02): ReLU(inplace=True)\n",
      "  (conv_transpose_2d_03): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_03): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_03): ReLU(inplace=True)\n",
      "  (conv_transpose_2d_04): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_04): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_04): ReLU(inplace=True)\n",
      "  (conv_transpose_2d_05): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "\n",
      "Discriminator: Discriminator(\n",
      "  (conv2d_01): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (leaky_relu_01): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (conv2d_02): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_02): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_relu_02): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (conv2d_03): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_03): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_relu_03): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (conv2d_04): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_2d_04): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_relu_04): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (conv2d_05): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (sigmoid_05): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator_model = Generator(latent_dimension=latent_dimension).to(device)\n",
    "print(f\"Generator: {generator_model}\\n\")\n",
    "\n",
    "discriminator_model = Discriminator().to(device)\n",
    "print(f\"Discriminator: {discriminator_model}\")\n",
    "\n",
    "criterion = torch.nn.BCELoss() # Binary cross entropy loss/ BCE\n",
    "optimizer_generator = torch.optim.Adam(generator_model.parameters(), lr=learning_rate, betas=(beta_01, 0.999))\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator_model.parameters(), lr=learning_rate, betas=(beta_01, 0.999))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
